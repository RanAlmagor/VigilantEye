# VigilantEye ğŸ‘ï¸â€ğŸ—¨ï¸  
**Real-Time UAV / Object Tracking Pipeline (C++17 + OpenCV)**  
![Status](https://img.shields.io/badge/status-active%20development-success)
![C++](https://img.shields.io/badge/C%2B%2B-17-blue)
![Build](https://img.shields.io/badge/build-CMake-informational)
![Deps](https://img.shields.io/badge/deps-vcpkg%20manifest-informational)
![OpenCV](https://img.shields.io/badge/OpenCV-required-brightgreen)

> **VigilantEye** is a modular, real-time vision pipeline designed to capture frames from multiple sources, run detection/tracking, and render an overlay/HUD â€” with a clean HAL-style architecture to support future sensors and actuators.

---

## ğŸ–¼ï¸ Screenshots
> Images are stored under `assets/screenshots/`

<img src="assets/screenshots/Shot1.jpeg" width="49%"/> <img src="assets/screenshots/Shot2.png" width="49%"/>

---

## âœ¨ Highlights
- **Pluggable Frame Sources (HAL/Sensors)**: webcam & video file today, RTSP/network source planned.
- **Vision Modules (Vision)**:
  - DNN-based detection (OpenCV DNN + YOLOv4-tiny model files in `config/models/`)
  - Motion detection
  - Object tracking interface ready for expansion
- **Pipeline-driven architecture** (Core): frame â†’ detect/track â†’ HUD/overlay.
- **Portable runtime config**: `config/` is copied next to the executable after build for easy runs.

---

## ğŸ§± Architecture (High-Level)

```mermaid
flowchart LR
  A[Frame Source<br/>Webcam / Video File / (RTSP planned)] --> B[Core::Pipeline]
  B --> C[Vision Algorithms<br/>DNN Detector / Motion Detector / Tracker]
  C --> D[UI::HUD Overlay]
  D --> E[Output Frame / Display]
```

---

## ğŸ“ Project Structure

```text
VigilantEye/
â”œâ”€ assets/
â”‚  â””â”€ screenshots/
â”‚     â”œâ”€ Shot1.jpeg
â”‚     â””â”€ Shot2.png
â”œâ”€ config/
â”‚  â”œâ”€ models/
â”‚  â”‚  â”œâ”€ coco.names.txt
â”‚  â”‚  â”œâ”€ yolov4-tiny.cfg
â”‚  â”‚  â””â”€ yolov4-tiny.weights
â”‚  â””â”€ system_config.json
â”œâ”€ include/
â”‚  â”œâ”€ Core/
â”‚  â”œâ”€ GeneralUtils/        (Logger, SafeQueue)
â”‚  â”œâ”€ HAL/
â”‚  â”‚  â”œâ”€ Actuators/        (IMotorController, VirtualMotor)
â”‚  â”‚  â””â”€ Sensors/          (IFrameSource, WebcamSource, VideoFileSource)
â”‚  â”œâ”€ UI/                  (HUD)
â”‚  â””â”€ Vision/              (DNNObjectDetector, MotionDetector, ObjectTracker, IVisionAlgorithm)
â”œâ”€ src/
â”‚  â”œâ”€ Core/                (Pipeline.cpp, SystemController.cpp)
â”‚  â”œâ”€ GeneralUtils/         (Logger.cpp)
â”‚  â”œâ”€ HAL/Sensors/          (WebcamSource.cpp, VideoFileSource.cpp)
â”‚  â””â”€ Vision/               (DNNObjectDetector.cpp, MotionDetector.cpp, ObjectTracker.cpp)
â”œâ”€ tests/
â”œâ”€ vcpkg/                   (submodule)
â”œâ”€ CMakeLists.txt
â”œâ”€ CMakePresets.json
â”œâ”€ vcpkg.json
â”œâ”€ demo.mp4
â””â”€ main.cpp
```

---

## âœ… Requirements
- **C++17 compiler**
- **CMake**
- **OpenCV** (installed via vcpkg manifest or system install)
- Windows recommended setup: **Visual Studio 2022** generator preset.

---

## âš¡ Build & Run (Windows / Visual Studio + vcpkg preset)

### 1) Clone with submodules
```bash
git clone --recurse-submodules <YOUR_REPO_URL>
cd VigilantEye
```

### 2) Configure & build (CMake Presets)
```bash
cmake --preset vs-debug
cmake --build --preset build-vs-debug
```

### 3) Run
After building, run the executable from the build output folder.

---

## ğŸ§© Configuration
Runtime configuration lives in:
- `config/system_config.json`

Use it to select the input source (webcam / video) and configure vision modules (detector/tracker parameters).  
*(If you want, paste the JSON here and Iâ€™ll document every field cleanly in the README.)*

---

## ğŸ§  Models (YOLOv4-tiny)
The repo includes model assets under:
- `config/models/yolov4-tiny.cfg`
- `config/models/yolov4-tiny.weights`
- `config/models/coco.names.txt`

The **DNNObjectDetector** loads these files using OpenCV DNN to perform object detection.

---

## ğŸ›£ï¸ Roadmap (Planned)
- [ ] **RTSPSource**: network/IP camera stream support
- [ ] UI: richer HUD (labels, confidence, tracking IDs, FPS)
- [ ] Actuators: real motor controller integration (beyond VirtualMotor)
- [ ] Tests: unit tests for utils + vision components
- [ ] Docs: diagrams + usage examples

---

## ğŸ§ª Notes
- This repository is **actively developed** â€” interfaces and modules are designed for growth as new sensors/algorithms are added.
- Contributions / suggestions are welcome (issues / PRs).

---

## ğŸ“œ License
Licensed under the **MIT License** (see `LICENSE`).
